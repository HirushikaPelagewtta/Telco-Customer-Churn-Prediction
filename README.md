# Customer Churn Prediction (Telco) â€” Production-Ready ML

A complete, business-focused churn prediction system built on the Kaggle Telco Customer Churn dataset. The repo includes exploratory data analysis, robust preprocessing, multiple model families (incl. CatBoost), hyperparameter tuning, threshold optimization, and a reproducible pipeline layout suitable for production.

> **Headline results:** Best model is **CatBoost** with **F1 â‰ˆ 64%**, **Recall â‰ˆ 71%**, **Precision â‰ˆ 58%**, **Accuracy â‰ˆ 79%** . High churn risk is driven by **month-to-month contracts**, **electronic check payments**, **short tenure**, and **higher monthly charges** .

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ Artifacts/                         # Saved models, encoders/scalers, reports
â”œâ”€â”€ Data/                              # Raw / interim / processed data (see data/raw and temp files)
â”œâ”€â”€ catboost_info/                     # CatBoost training logs/metadata
â”œâ”€â”€ artifacts/                         # (pipeline run outputs â€“ splits, models, metrics)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                           # Raw CSV(s)
â”œâ”€â”€ pipelines/                         # Orchestrated steps for ingestion/splitting/training
â”œâ”€â”€ src/                               # Core library code used by pipelines
â”œâ”€â”€ utils/                             # Helpers (I/O, metrics, config, etc.)
â”œâ”€â”€ 0_Handling_Missing_Values.ipynb    # EDA & data cleaning
â”œâ”€â”€ 1_Handling_Outliers.ipynb
â”œâ”€â”€ 2_Feature_Binning.ipynb
â”œâ”€â”€ 3_Encoding_And_Scaling.ipynb
â”œâ”€â”€ 1_Base_Model_Training.ipynb        # Baselines + initial eval
â”œâ”€â”€ 2_kfold_validation.ipynb
â”œâ”€â”€ 3_Multi_model_training.ipynb       # RF/XGB/CatBoost training
â”œâ”€â”€ 4_Hyperparam_tuning.ipynb
â”œâ”€â”€ 5_Threshold_optimization.ipynb
â”œâ”€â”€ 6_Using_the_Best_Model.ipynb       # Inference/serving demo
â”œâ”€â”€ config.yaml                        # Centralized configuration
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ Makefile                           # Optional convenience commands
â”œâ”€â”€ .env                               # Local environment variables (optional)
â””â”€â”€ temp_imputed.csv                   # Intermediate artifact from preprocessing
```

> The Jupyter notebooks show the full **data â†’ features â†’ model â†’ tune â†’ threshold â†’ use** workflow, while `pipelines/`, `src/`, and `utils/` contain reusable code used to make the process repeatable.

---

## ğŸ¯ Problem & Business Framing

* **Goal:** Predict which customers will churn so the business can target retention actions.
* **Dataset:** Telco Customer Churn (â‰ˆ7,043 rows, 21 features; label: `Churn`)&#x20;
* **Deliverables:** Cleaned features, multiple trained models (LogReg/DT/RF/XGBoost/CatBoost), and evaluation using class-imbalance-aware metrics (Precision, Recall, F1, Accuracy) .

### Why it matters

At the chosen decision threshold, **\~71%** of at-risk customers can be captured (Recall), and **\~58%** of contacted customers are true churners (Precision), improving campaign ROI .
A cost snapshot in the report shows a positive **net expected ROI** when using these predictions to drive targeted offers .

---

## âœ… Results (Summary)

| Model               | F1 (test)   |
| ------------------- | ----------- |
| Logistic Regression | \~79.9%     |
| Decision Tree       | \~80.0%     |
| Random Forest       | \~84.7%     |
| XGBoost             | \~84.8%     |
| **CatBoost**        | **\~85.6%** |

*As reported in the executive summary comparison table* .

**Key churn drivers:** month-to-month contracts, electronic check payments, short tenure, high monthly charges .
**Recommended actions:** incentives to move to annual contracts, value-add bundles (security/tech support), prioritize outreach to top decile risk, tailor channel by payment method .

---

## ğŸ› ï¸ Setup

```bash
# 1) Create and activate a virtual environment
python -m venv .venv
# Windows: .venv\Scripts\activate
# Mac/Linux:
source .venv/bin/activate

# 2) Install dependencies
pip install -r requirements.txt

# 3) (Optional) set environment variables
cp .env.example .env  # if provided

# 4) Verify
python -c "import sklearn, xgboost, catboost; print('ok')"
```

---

## ğŸš€ How to Run

### Option A â€” Reproduce the workflow with notebooks

Open the notebooks in this order:

1. `0_Handling_Missing_Values.ipynb` â†’ cleaning & imputations
2. `1_Handling_Outliers.ipynb`
3. `2_Feature_Binning.ipynb`
4. `3_Encoding_And_Scaling.ipynb`
5. `1_Base_Model_Training.ipynb`
6. `2_kfold_validation.ipynb`
7. `3_Multi_model_training.ipynb`
8. `4_Hyperparam_tuning.ipynb`
9. `5_Threshold_optimization.ipynb`
10. `6_Using_the_Best_Model.ipynb` â†’ load best model, run inference

Intermediate outputs and trained models are saved under `Artifacts/` or `artifacts/`.

### Option B â€” Pipeline scripts (if provided)

If the repo includes CLI entry points for the modules in `pipelines/` and `src/`, you can wire them with the `Makefile`:

```bash
# Examples (adjust targets to what's implemented in your Makefile)
make ingest         # read raw data into data/raw
make split          # train/valid/test split
make train          # train baseline and ensemble models
make tune           # hyperparameter search
make evaluate       # metrics & confusion matrix
make predict        # run inference with the best model
```

Configuration such as paths, feature lists, and model params is centralized in **`config.yaml`**.

---

## ğŸ“Š Evaluation & Thresholding

* **Metrics:** Precision, Recall, F1, Accuracy (stratified CV and test set).
* **Class imbalance:** addressed via threshold tuning and evaluation emphasis on Recall / F1.
* **Threshold optimization:** `5_Threshold_optimization.ipynb` chooses an operating point that balances business cost/benefit; see the ROI table and recommendations in the report .

---

## ğŸ§  Feature Engineering (Highlights)

* Tenure binning (New / Established / Loyal), categorical encoding, numeric scaling .
* Payment type, contract type, and service add-ons captured to expose churn signals (drivers listed above).

---

## ğŸ§ª Reusing the Best Model

Use `6_Using_the_Best_Model.ipynb` to load the exported pipeline and run batch or single-row predictions. For programmatic usage, import the packaged pipeline from `src/` (e.g., `from src.pipeline import load_model, predict` if present) and pass a dataframe with the same schema as the training data.

---

## ğŸ“ˆ Business Playbook (from the report)

* **Convert** month-to-month â†’ annual with targeted incentives.
* **Bundle** tech-support/security add-ons for at-risk segments.
* **Prioritize** top-decile churn probability for maximum ROI.
* **Personalize** outreach channel based on payment method (e.g., electronic check â†’ email reminders/offers).
  All are summarized and supported in the executive summary .

---

## ğŸ”’ Reproducibility & Hygiene

* All transformations are embedded into scikit-learn/CatBoost pipelines for **train/test parity** and **one-line inference** .
* Parameters and paths live in `config.yaml`.
* Deterministic splits via fixed seeds (where applicable).
* Artifacts versioned under `Artifacts/` or `artifacts/`.

---

## ğŸ§­ Roadmap

* Add experiment tracking (MLflow or Weights & Biases).
* Export a lightweight FastAPI service for real-time scoring.
* Implement calibration and cost-sensitive training variants.
* Add unit tests (pytest) for `src/` and schema checks (pandera).

---

## ğŸ“œ Citation

If you use or reference the results/figures in this repo, please cite the accompanying **Executive Summary Report** for metrics, drivers, and business analysis:   .

---

**Author:** H. P. Pelagewatta
**Project:** Mini Project 0 â€” Advanced Telco: Customer Churn Prediction (Production-Ready ML)&#x20;
