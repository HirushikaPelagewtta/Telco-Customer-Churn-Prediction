{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "566cc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree   import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    recall_score\n",
    ")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2b7ff",
   "metadata": {},
   "source": [
    "### 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d60c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('Artifacts/X_train.npz')['arr_0']\n",
    "Y_train = np.load('Artifacts/Y_train.npz')['arr_0']\n",
    "X_test = np.load('Artifacts/X_test.npz')['arr_0']\n",
    "Y_test = np.load('Artifacts/Y_test.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7106ae1",
   "metadata": {},
   "source": [
    "### 2. Define Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a56b0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids for hyperparameter tuning\n",
    "\n",
    "lr_param_grid ={\n",
    "    'max_iter': [500, 1000, 5000, 10000],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "    \n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [4, 6, 8, 12, 16, 20],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [6, 8, 12, 16],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 250, 300],\n",
    "    'max_depth': [3, 4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "cat_param_grid ={\n",
    "    'iterations': [200, 500, 1000],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'border_count': [32, 64, 128]\n",
    "}\n",
    "\n",
    "param_grids ={\n",
    "    'logistic_regression': lr_param_grid,\n",
    "    'decision_tree': dt_param_grid,\n",
    "    'random_forest': rf_param_grid,\n",
    "    'xgboost' : xgb_param_grid,\n",
    "    'catboost' : cat_param_grid\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c665807",
   "metadata": {},
   "source": [
    "### 3. Define Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "880b53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\n",
    "    'logistic_regression': LogisticRegression(),\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "    'random_forest': RandomForestClassifier(),\n",
    "    'xgboost' : XGBClassifier(),\n",
    "    'catboost' : CatBoostClassifier(verbose=0, random_state=42)    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ca872",
   "metadata": {},
   "source": [
    "### 4. Configure K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "610afc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(\n",
    "    n_splits=6,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e054c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training logistic_regression...\n",
      "Fitting grid search for logistic_regression\n",
      "logistic_regression best parameters: {'solver': 'lbfgs', 'max_iter': 500, 'C': 10}\n",
      "logistic_regression best score: 0.7986\n",
      "\n",
      "Training decision_tree...\n",
      "Fitting grid search for decision_tree\n",
      "decision_tree best parameters: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 12, 'criterion': 'entropy'}\n",
      "decision_tree best score: 0.8014\n",
      "\n",
      "Training random_forest...\n",
      "Fitting grid search for random_forest\n",
      "random_forest best parameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 16, 'criterion': 'log_loss'}\n",
      "random_forest best score: 0.8481\n",
      "\n",
      "Training xgboost...\n",
      "Fitting grid search for xgboost\n",
      "xgboost best parameters: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "xgboost best score: 0.8484\n",
      "\n",
      "Training catboost...\n",
      "Fitting grid search for catboost\n",
      "catboost best parameters: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 500, 'depth': 8, 'border_count': 32}\n",
      "catboost best score: 0.8538\n"
     ]
    }
   ],
   "source": [
    "grid_search_results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,            # more iterations for wider search\n",
    "        scoring='f1',   # change to 'f1', 'roc_auc' if needed\n",
    "        cv=cv,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"Fitting grid search for {model_name}\")\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    grid_search_results[model_name] = grid_search\n",
    "\n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} best score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dcc69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Models\n",
    "# models = {\n",
    "#     'logistic_regression': LogisticRegression(),\n",
    "#     'decision_tree': DecisionTreeClassifier(),\n",
    "#     'random_forest': RandomForestClassifier(),\n",
    "#     'xgboost': XGBClassifier(),\n",
    "#     'catboost': CatBoostClassifier(verbose=0, random_state=42)\n",
    "# }\n",
    "\n",
    "# # Expanded parameter grids\n",
    "# param_grids = {\n",
    "#     'logistic_regression': {\n",
    "#         'max_iter': [500, 1000, 5000, 10000],\n",
    "#         'C': [0.01, 0.1, 1, 10],          # regularization strength\n",
    "#         'solver': ['lbfgs', 'liblinear']  # solver options\n",
    "#     },\n",
    "#     'decision_tree': {\n",
    "#         'max_depth': [4, 6, 8, 12, 16, 20],\n",
    "#         'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#         'min_samples_split': [2, 5, 10],\n",
    "#         'min_samples_leaf': [1, 2, 4]\n",
    "#     },\n",
    "#     'random_forest': {\n",
    "#         'n_estimators': [100, 200, 300],\n",
    "#         'max_depth': [6, 8, 12, 16],\n",
    "#         'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#         'min_samples_split': [2, 5, 10],\n",
    "#         'min_samples_leaf': [1, 2, 4]\n",
    "#     },\n",
    "#     'xgboost': {\n",
    "#         'n_estimators': [100, 200, 250, 300],\n",
    "#         'max_depth': [3, 4, 6, 8, 10],\n",
    "#         'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'gamma': [0, 0.1, 0.2]\n",
    "#     },\n",
    "#     'catboost': {\n",
    "#         'iterations': [200, 500, 1000],\n",
    "#         'depth': [4, 6, 8, 10],\n",
    "#         'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#         'l2_leaf_reg': [1, 3, 5, 7],\n",
    "#         'border_count': [32, 64, 128]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Split dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Randomized search for each model\n",
    "# best_models = {}\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     print(f\"Running RandomizedSearchCV for {name}...\")\n",
    "    \n",
    "#     search = RandomizedSearchCV(\n",
    "#         estimator=model,\n",
    "#         param_distributions=param_grids[name],\n",
    "#         n_iter=20,            # more iterations for wider search\n",
    "#         scoring='accuracy',   # change to 'f1', 'roc_auc' if needed\n",
    "#         cv=3,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "    \n",
    "#     search.fit(X_train, y_train)\n",
    "#     best_models[name] = search.best_estimator_\n",
    "    \n",
    "#     # Evaluate\n",
    "#     y_pred = search.predict(X_test)\n",
    "#     print(f\"Best Parameters: {search.best_params_}\")\n",
    "#     print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "#     print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "#     print(\"--------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bprmls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
